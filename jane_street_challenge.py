# -*- coding: utf-8 -*-
"""Jane_Street_Challenge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZHgrPfcuylObf2jETl6am-1lLqLjIYoL
"""

from google.colab import drive
import os
import pandas as pd
import numpy as np
import sklearn

drive.mount("/content/gdrive")

os.chdir("/content/gdrive/MyDrive/Colab Notebooks/Kaggle_Competition")

df_features = pd.read_csv('features.csv')

df_features

df_features.shape

df_train = pd.read_csv('train.csv', nrows=100000)

df_train.shape

df_example_test = pd.read_csv('example_test.csv')
df_example_test.head()

df_example_sub = pd.read_csv('example_sample_submission.csv')
df_example_sub.head()

df_train.head()

df_baseline = df_train.drop(['resp_1', 'resp_2', 'resp_3', 'resp_4'], axis = 1)

df_baseline.loc[df_baseline.resp > 0, 'resp'] = 1
df_baseline.loc[df_baseline.resp == 0, 'resp'] = 'NA'
df_baseline.loc[df_baseline.resp < 0, 'resp'] = 0

df_baseline = df_baseline.rename(columns={"resp":"action"})

df_baseline.head()

cols_to_order = ['date','ts_id','action']
new_columns = (df_baseline.columns.drop(cols_to_order).tolist()) + cols_to_order 
df_baseline = df_baseline[new_columns]

print(df_baseline.shape)
df_baseline.head()

df_baseline.isna().sum()

a = df_baseline.columns[df_baseline.isnull().any()]
a = a.tolist()

df_baseline.fillna(df_baseline[a].median(), inplace = True)

df_baseline.isna().sum()

print(df_baseline.shape)
df_baseline.head()

"""Pre-Processing - PCA"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

l = df_baseline.iloc[:,1:131].columns.to_list()

scaled = scaler.fit_transform(df_baseline[l])

scaled.shape

loading_matrix = pd.DataFrame(scaled, columns=l)

loading_matrix.head()

df_baseline.update(other = loading_matrix)

df_baseline.head()

from numpy import loadtxt
from keras.models import Sequential
from keras.layers import Dense

# split into input (X) and output (y) variables
X = df_baseline.iloc[:,1:131]

y = df_baseline.iloc[:,133:134]

y = y.astype(np.float32)
X = X.astype(np.float32)
print(X.shape)
print(y.shape)
print(X.dtypes)
print(y.dtypes)

model = Sequential()

model.add(Dense(32, input_dim = 130, activation = 'relu' ))
model.add(Dense(12, activation = 'relu'))
model.add(Dense(1, activation = 'sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','AUC'])

model.fit(X, y, epochs=25, batch_size=4000)

_, accuracy = model.evaluate(X, y)
print('Accuracy: %.2f' % (accuracy*100))

# make probability predictions with the model
predictions = model.predict(X)
# round predictions 
rounded = [round(x[0]) for x in predictions]

from sklearn import metrics

y_a = df_baseline['action']

y_b = y['action']

from collections import Counter

print(Counter(y_b)) # y_true must be your labels
print(Counter(y_a))

#yfpr, tpr, thresholds = metrics.roc_curve(y_a,y_b, pos_label=2)

metrics.auc(fpr, tpr)

#df_baseline['prediction'] = predictions

#convert when above a certain prediction threshold to 1 or 0.

#df_baseline.head()

#df_baseline['prediction'].dtype

#df_baseline['action_prediction'] = df_baseline['prediction'].apply(lambda x: 1 if x >= 0.5 else 0)

#df_baseline.head()

#df_baseline['prediction_accuracy'] = np.where((df_baseline['action'] == df_baseline['action_prediction']), 'Match', 'No Match')

#df_baseline.head()

#df_baseline['prediction_accuracy'].value_counts()

#Match = (len(df_baseline[df_baseline.prediction_accuracy == 'Match']))
#No_Match = (len(df_baseline[df_baseline.prediction_accuracy == 'No Match'])) 

#print("The Match accuracy is:" + str(((Match)/(Match + No_Match)*100)))

#print("The No Match accuracy is:" + str(((No_Match)/(Match + No_Match)*100)))

#df_resp = df_train[["resp"]]
#df_portfolio = pd.merge(df_resp, df_baseline, right_index = True, left_index = True)

#df_portfolio = df_portfolio.drop(df_portfolio.columns[2:134], axis=1)

#df_portfolio

#Check return claimed of the trades
#(df_portfolio['resp'][(df_portfolio['prediction_accuracy'] == 'Match')].sum())/len(df_portfolio['prediction_accuracy'] == 'Match') *100

#Evaluation Metric
#((df_portfolio['resp'][(df_portfolio['prediction_accuracy'] == 'Match')].sum())/(df_portfolio['resp'][(df_portfolio['action'] == 1)].sum()))

"""Try at 0.6"""

#df_baseline_6 = df_baseline.copy()

#Try at .0.6
#df_baseline_6['action_prediction'] = df_baseline['prediction'].apply(lambda x: 1 if x >= 0.95 else 0)
#df_baseline_6['prediction_accuracy'] = np.where((df_baseline_6['action'] == df_baseline_6['action_prediction']), 'Match', 'No Match')

#df_portfolio_6 = pd.merge(df_resp, df_baseline_6, right_index = True, left_index = True)

#df_portfolio_6 = df_portfolio_6.drop(df_portfolio_6.columns[2:134], axis=1)

#df_portfolio_6

"""Algorithm 2"""

#from sklearn.linear_model import LogisticRegression

#model = LogisticRegression(solver='liblinear', random_state=0)

#X.shape

#y.shape
#y = np.ravel(y)

#model.fit(X,y)

#model.score(X, y)

"""Algorithm 3"""

#from xgboost import XGBClassifier

#model = XGBClassifier()
#model.fit(X, y)

#y_pred = model.predict(X)

#predictions = [round(value) for value in y_pred]

#from sklearn.metrics import accuracy_score

#accuracy = accuracy_score(y, predictions)
#print("Accuracy: %.2f%%" % (accuracy * 100.0))